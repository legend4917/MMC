\chapter{结束语}
\section{本文工作小结}
本文就如何将SVM中的间隔最大化学习策略和核技巧应用到无监督的聚类学习中进行了深入研究。首先，分别从SVM的主问题和对偶问题出发，分析了SVM的学习问题，讨论了模型的构建、优化问题的推导以及二者之间的关系等问题，并研究了间隔最大化学习策略和核技巧在SVM中的应用方法。

其次，将SVM推广到无监督学习中，为无类别标记的训练数据添加一组标记，使得其经过SVM训练学习后，能得到最大的间隔，这就是最大间隔聚类MMC。MMC通过使用一系列线性约束来替换原始非凸整形规划问题的非凸约束，得到凸整形规划问题，然后再松弛其中的整形约束，从而得到最终的SDP问题，并能通过现有的半定规划工具包进行求解。但MMC在松弛约束的过程中会损失部分参数空间，并且与其它核方法一样，寻找合适的核函数是个比较困难的问题。

进一步，在MMC的基础上引入有监督和半监督学习中多核学习的思想，使用多个核函数的非负线性组合得到新的基核，并使用此基核进行训练、学习。并针对MMC中出现的非凸整形规划问题，MKC应用割平面算法，构造一系列逐渐逼近该问题的序列，并且序列中的每个问题都可以使用CCCP求解。MKC最终能在训练数据上找到最大间隔超平面、最适当的类标记组合以及最优的核函数组合。

最后，在对MMC和MKC模型进行详细探讨之后，通过实验来验证其性能的优越性。本文使用UCI上的数据集，对MMC、MKC、k均值和谱聚类的聚类精度进行比较，并对MKC的聚类性能作出评价。

\section{进一步的工作}
本文深入分析了MMC和MKC的聚类原理以及模型推导过程，实现了间隔最大化学习策略和核技巧向聚类的推广，并引入有监督和半监督学习中的多核思想，最终实现基于间隔最大化学习策略和核技巧的多核学习聚类模型。在此基础上，本文还有以下工作可以进一步拓展和完善：
\begin{enumerate}[fullwidth,itemindent=24pt]
  \item 选用计算能力更强的设备，使用更多的数据集对模型性能进行测试，以便客观的评价模型的性能。
  \item 分析MKC算法的时间复杂度和聚类精度，为MKC算法的收敛速度和聚类精度提供理论支持。
  \item 考虑多分类SVM模型，并在此基础上尝试将MKC推广为多类分类模型，再进行相关实验验证多类MKC模型的性能。
\end{enumerate}